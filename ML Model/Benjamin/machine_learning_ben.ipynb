{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.facecolor'] = 'white' # Since I use a dark IDE\n",
    "\n",
    "# To allow multiple outputs per cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.model_selection  import train_test_split, GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/benjamintan/Library/CloudStorage/OneDrive-TheUniversityofWesternAustralia/Master of Data Science/Year 2/Semester 2/CITS5553/CITS5553-Capstone-Project/ML Model/Benjamin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full data\n",
    "wba_data = pd.read_csv(\"./Data/wba_data_CLEAN.csv\")\n",
    "\n",
    "## Normal\n",
    "X_train_norm = pd.read_csv('./Data/Normal/X_train.csv')\n",
    "y_train_norm = pd.read_csv('./Data/Normal/y_train.csv')\n",
    "X_test_norm = pd.read_csv('./Data/Normal/X_test.csv')\n",
    "y_test_norm = pd.read_csv('./Data/Normal/y_test.csv')\n",
    "\n",
    "## SMOTE\n",
    "X_train_smote = pd.read_csv('./Data/Smote Large/X_train_smote.csv')\n",
    "y_train_smote = pd.read_csv('./Data/Smote Large/y_train_smote.csv')\n",
    "X_test_smote = pd.read_csv('./Data/Smote Large/X_test_smote.csv')\n",
    "y_test_smote = pd.read_csv('./Data/Smote Large/y_test_smote.csv')\n",
    "\n",
    "## Oversampling\n",
    "X_train_over = pd.read_csv('./Data/Oversampling/X_train_over.csv')\n",
    "y_train_over = pd.read_csv('./Data/Oversampling/y_train_over.csv')\n",
    "X_test_over = pd.read_csv('./Data/Oversampling/X_test_over.csv')\n",
    "y_test_over = pd.read_csv('./Data/Oversampling/y_test_over.csv')\n",
    "\n",
    "## ADASYN\n",
    "X_train_adasyn = pd.read_csv('./Data/Adasyn Large/X_train_adasyn.csv')\n",
    "y_train_adasyn = pd.read_csv('./Data/Adasyn Large/y_train_adasyn.csv')\n",
    "X_test_adasyn = pd.read_csv('./Data/Adasyn Large/X_test_adasyn.csv')\n",
    "y_test_adasyn = pd.read_csv('./Data/Adasyn Large/y_test_adasyn.csv')\n",
    "\n",
    "## Generated\n",
    "X_train_gen = pd.read_csv('./Data/VAE (Experimental)/X_gen_train.csv', usecols = X_train_norm.columns)\n",
    "y_train_gen = pd.read_csv('./Data/VAE (Experimental)/X_gen_train.csv', usecols = ['OverallPoF'])\n",
    "X_test_gen = pd.read_csv('./Data/VAE (Experimental)/X_gen_test.csv', usecols = X_train_norm.columns)\n",
    "y_test_gen = pd.read_csv('./Data/VAE (Experimental)/X_gen_test.csv', usecols=['OverallPoF'])\n",
    "\n",
    "\n",
    "\n",
    "dfs = [X_train_norm,y_train_norm,X_test_norm,y_test_norm,\n",
    "X_train_smote, y_train_smote,X_test_smote,y_test_smote,\n",
    "X_train_over,y_train_over,X_test_over,y_test_over,\n",
    "X_train_adasyn,y_train_adasyn,X_test_adasyn,y_test_adasyn]\n",
    "\n",
    "# Delete Unnamed: 0 columns if they are there\n",
    "for df in dfs:\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_select = ['TPP', 'TympType', 'OAE1', 'OAE1.4', 'OAE2', 'OAE2.8', 'OAE4','f(408.4789)', 'f(2593.6791)', 'f(2378.4142)', 'f(2310.7054)', 'f(7127.1897)', 'f(865.5366)', 'f(6727.1713)', 'f(226.0000)', 'f(458.5020)', 'f(500.0000)', 'f(1029.3022)', 'f(5993.2283)', 'f(1887.7486)', 'f(1373.9536)', 'f(667.4199)', 'f(2747.9073)', 'f(1296.8396)', 'f(577.6763)', 'f(1155.3527)', 'f(1090.5077)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, y_train, X_test, y_test, vars = 'reduced', seed=42, cv_folds=5):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    if vars == 'full':\n",
    "        pass\n",
    "    elif vars == 'reduced':\n",
    "        feat_select = ['TPP', 'TympType', 'OAE1', 'OAE1.4', 'OAE2', 'OAE2.8', 'OAE4','f(408.4789)', 'f(2593.6791)', 'f(2378.4142)', 'f(2310.7054)', 'f(7127.1897)', 'f(865.5366)', 'f(6727.1713)', 'f(226.0000)', 'f(458.5020)', 'f(500.0000)', 'f(1029.3022)', 'f(5993.2283)', 'f(1887.7486)', 'f(1373.9536)', 'f(667.4199)', 'f(2747.9073)', 'f(1296.8396)', 'f(577.6763)', 'f(1155.3527)', 'f(1090.5077)']\n",
    "        X_train = X_train[feat_select]\n",
    "        X_test = X_test[feat_select]\n",
    "    elif vars == 'freqs':\n",
    "        freq_cols = [c for c in X_train.columns if c[:2] == \"f(\"]\n",
    "        X_train = X_train[freq_cols]\n",
    "        X_test = X_test[freq_cols]\n",
    "    elif vars == 'conts':\n",
    "        cont_cols = [c for c in X_train.columns if c[:2] != \"f(\"]\n",
    "        X_train = X_train[cont_cols]\n",
    "        X_test = X_test[cont_cols]\n",
    "    elif vars == 'freqs_reduced':\n",
    "        feat_select = ['f(2593.6791)', 'f(2378.4142)', 'f(2310.7054)', 'f(7127.1897)', 'f(865.5366)', 'f(6727.1713)', 'f(226.0000)', 'f(458.5020)', 'f(500.0000)', 'f(1029.3022)', 'f(5993.2283)', 'f(1887.7486)', 'f(1373.9536)', 'f(667.4199)', 'f(2747.9073)', 'f(1296.8396)', 'f(577.6763)', 'f(1155.3527)', 'f(1090.5077)']\n",
    "        X_train = X_train[feat_select]\n",
    "        X_test = X_test[feat_select]\n",
    "\n",
    "\n",
    "    # Creating hyperparameters ditionary\n",
    "    saga_grid = {'solver': ['saga'],\n",
    "                    'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "                    'l1_ratio': [r/10 for r in list(range(0,10,1))]\n",
    "                    }\n",
    "    liblinear_grid = {'solver': ['liblinear'],\n",
    "                        'penalty': ['l1', 'l2']}\n",
    "    \n",
    "    parameters = [saga_grid, liblinear_grid]\n",
    "\n",
    "    # Fit GridSearch\n",
    "    grid_log_reg = GridSearchCV(\n",
    "        LogisticRegression(random_state=seed),\n",
    "        parameters, \n",
    "        cv = 2\n",
    "    )\n",
    "    grid_log_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Extract best estimator\n",
    "    print(\"Best model: {}\".format(grid_log_reg.best_estimator_))\n",
    "    log_reg = grid_log_reg.best_estimator_\n",
    "\n",
    "    # Cross validation\n",
    "    cv_scores = cross_val_score(log_reg, X_train, y_train, cv=cv_folds)\n",
    "    print(\"{0}-fold cross validation:\\n  accuracy: {1}\\n  std dev: {2}\".format(cv_folds, round(cv_scores.mean(), 2), round(cv_scores.std(), 2)))\n",
    "\n",
    "    # Train set\n",
    "    print(\"Training Data\")\n",
    "    y_train_pred = log_reg.predict(X_train)\n",
    "    print(classification_report(y_train_pred, y_train))\n",
    "\n",
    "    # Test set\n",
    "    print(\"Test Data\")\n",
    "    y_test_pred = log_reg.predict(X_test)\n",
    "    print(classification_report(y_test_pred, y_test))\n",
    "\n",
    "    # Coefficients\n",
    "    print(\"Coefficients:\")\n",
    "    coefs = zip(list(X_train.columns), log_reg.coef_.tolist()[0])\n",
    "\n",
    "        # Print top 5 coefficients\n",
    "    coefs = sorted(coefs, key = lambda x: abs(x[1]), reverse = True)\n",
    "    for coef in coefs[:5]:\n",
    "        print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machine(X_train, y_train, X_test, y_test, vars = 'reduced', seed=42, cv_folds=5):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    if vars == 'full':\n",
    "        pass\n",
    "    elif vars == 'reduced':\n",
    "        feat_select = ['TPP', 'TympType', 'OAE1', 'OAE1.4', 'OAE2', 'OAE2.8', 'OAE4','f(408.4789)', 'f(2593.6791)', 'f(2378.4142)', 'f(2310.7054)', 'f(7127.1897)', 'f(865.5366)', 'f(6727.1713)', 'f(226.0000)', 'f(458.5020)', 'f(500.0000)', 'f(1029.3022)', 'f(5993.2283)', 'f(1887.7486)', 'f(1373.9536)', 'f(667.4199)', 'f(2747.9073)', 'f(1296.8396)', 'f(577.6763)', 'f(1155.3527)', 'f(1090.5077)']\n",
    "        X_train = X_train[feat_select]\n",
    "        X_test = X_test[feat_select]\n",
    "    elif vars == 'freqs':\n",
    "        freq_cols = [c for c in X_train.columns if c[:2] == \"f(\"]\n",
    "        X_train = X_train[freq_cols]\n",
    "        X_test = X_test[freq_cols]\n",
    "    elif vars == 'conts':\n",
    "        cont_cols = [c for c in X_train.columns if c[:2] != \"f(\"]\n",
    "        X_train = X_train[cont_cols]\n",
    "        X_test = X_test[cont_cols]\n",
    "    elif vars == 'freqs_reduced':\n",
    "        feat_select = ['f(2593.6791)', 'f(2378.4142)', 'f(2310.7054)', 'f(7127.1897)', 'f(865.5366)', 'f(6727.1713)', 'f(226.0000)', 'f(458.5020)', 'f(500.0000)', 'f(1029.3022)', 'f(5993.2283)', 'f(1887.7486)', 'f(1373.9536)', 'f(667.4199)', 'f(2747.9073)', 'f(1296.8396)', 'f(577.6763)', 'f(1155.3527)', 'f(1090.5077)']\n",
    "        X_train = X_train[feat_select]\n",
    "        X_test = X_test[feat_select]\n",
    "\n",
    "    # Creating hyperparameters ditionary\n",
    "    params_linear = {'C': [0.1, 1, 10, 100, 1000], \n",
    "                'kernel': ['linear']} \n",
    "    params_nonlinear = {'C': [0.1, 1, 10, 100, 1000],\n",
    "                'gamma': [1, 0.1, 0.01, 0.001, 0.0001,'auto'], \n",
    "                'kernel': ['poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "    parameters = [params_linear, params_nonlinear]\n",
    "\n",
    "\n",
    "    # Fit GridSearch\n",
    "    grid_svm = GridSearchCV(\n",
    "        SVC(random_state=seed),\n",
    "        parameters, \n",
    "        cv = 2\n",
    "    )\n",
    "    grid_svm.fit(X_train, y_train)\n",
    "\n",
    "    # Extract best estimator\n",
    "    print(\"Best model: {}\".format(grid_svm.best_estimator_))\n",
    "    svm = grid_svm.best_estimator_\n",
    "\n",
    "    # Cross validation\n",
    "    cv_scores = cross_val_score(svm, X_train, y_train, cv=cv_folds)\n",
    "    # print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_scores.mean(), cv_scores.std()))\n",
    "    print(\"{0}-fold cross validation:\\n  accuracy: {1}\\n  std dev: {2}\".format(cv_folds, round(cv_scores.mean(), 2), round(cv_scores.std(), 2)))\n",
    "\n",
    "    # Train set\n",
    "    print(\"Training Data\")\n",
    "    y_train_pred = svm.predict(X_train)\n",
    "    print(classification_report(y_train_pred, y_train))\n",
    "\n",
    "    # Test set\n",
    "    print(\"Test Data\")\n",
    "    y_test_pred = svm.predict(X_test)\n",
    "    print(classification_report(y_test_pred, y_test))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(l1_ratio=0.0, penalty='none', random_state=42, solver='saga')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.95\n",
      "  std dev: 0.03\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       165\n",
      "           1       0.83      0.96      0.89        26\n",
      "\n",
      "    accuracy                           0.97       191\n",
      "   macro avg       0.91      0.97      0.94       191\n",
      "weighted avg       0.97      0.97      0.97       191\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        41\n",
      "           1       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.98        48\n",
      "   macro avg       0.94      0.99      0.96        48\n",
      "weighted avg       0.98      0.98      0.98        48\n",
      "\n",
      "Coefficients:\n",
      "('OAE1.4', -0.1368159934662426)\n",
      "('OAE2', -0.1111201604628667)\n",
      "('OAE1', -0.10548826300117627)\n",
      "('OAE2.8', -0.06802635110824189)\n",
      "('OAE4', -0.055145739530662534)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_norm, y_train_norm, X_test_norm, y_test_norm, vars='reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(l1_ratio=0.0, penalty='l1', random_state=42, solver='saga')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.93\n",
      "  std dev: 0.03\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       169\n",
      "           1       0.63      0.86      0.73        22\n",
      "\n",
      "    accuracy                           0.93       191\n",
      "   macro avg       0.81      0.90      0.84       191\n",
      "weighted avg       0.94      0.93      0.93       191\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        43\n",
      "           1       0.62      1.00      0.77         5\n",
      "\n",
      "    accuracy                           0.94        48\n",
      "   macro avg       0.81      0.97      0.87        48\n",
      "weighted avg       0.96      0.94      0.94        48\n",
      "\n",
      "Coefficients:\n",
      "('f(1090.5077)', -2.717236683194348)\n",
      "('f(1155.3527)', -2.226855022335862)\n",
      "('f(1296.8396)', -2.1391507081074383)\n",
      "('f(1373.9536)', -1.4904850824880262)\n",
      "('f(1029.3022)', -1.2748061917734992)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_norm, y_train_norm, X_test_norm, y_test_norm, vars='freqs_reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(l1_ratio=0.0, penalty='none', random_state=42, solver='saga')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.95\n",
      "  std dev: 0.03\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       165\n",
      "           1       0.83      0.96      0.89        26\n",
      "\n",
      "    accuracy                           0.97       191\n",
      "   macro avg       0.91      0.97      0.94       191\n",
      "weighted avg       0.97      0.97      0.97       191\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        41\n",
      "           1       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.98        48\n",
      "   macro avg       0.94      0.99      0.96        48\n",
      "weighted avg       0.98      0.98      0.98        48\n",
      "\n",
      "Coefficients:\n",
      "('OAE1.4', -0.13122325142380506)\n",
      "('OAE2', -0.10617872189254472)\n",
      "('OAE1', -0.1018423600386256)\n",
      "('OAE2.8', -0.05954917264912355)\n",
      "('OAE4', -0.04830993718598464)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_norm, y_train_norm, X_test_norm, y_test_norm, vars='conts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.97\n",
      "  std dev: 0.04\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       169\n",
      "           1       1.00      0.99      1.00       172\n",
      "\n",
      "    accuracy                           1.00       341\n",
      "   macro avg       1.00      1.00      1.00       341\n",
      "weighted avg       1.00      1.00      1.00       341\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        29\n",
      "           1       1.00      0.94      0.97        32\n",
      "\n",
      "    accuracy                           0.97        61\n",
      "   macro avg       0.97      0.97      0.97        61\n",
      "weighted avg       0.97      0.97      0.97        61\n",
      "\n",
      "Coefficients:\n",
      "('TympType', 9.2869966023568)\n",
      "('f(2747.9073)', 0.7052166099510111)\n",
      "('OAE1.4', -0.361744080704117)\n",
      "('OAE4', -0.357868142991216)\n",
      "('OAE2', -0.31898601867111515)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_over, y_train_over, X_test_over, y_test_over, vars='reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.87\n",
      "  std dev: 0.03\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       183\n",
      "           1       0.83      0.90      0.86       158\n",
      "\n",
      "    accuracy                           0.87       341\n",
      "   macro avg       0.87      0.87      0.87       341\n",
      "weighted avg       0.87      0.87      0.87       341\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89        30\n",
      "           1       0.90      0.87      0.89        31\n",
      "\n",
      "    accuracy                           0.89        61\n",
      "   macro avg       0.89      0.89      0.89        61\n",
      "weighted avg       0.89      0.89      0.89        61\n",
      "\n",
      "Coefficients:\n",
      "('f(1373.9536)', -1.9858702246942666)\n",
      "('f(1296.8396)', -1.8315633361540868)\n",
      "('f(1887.7486)', -1.2613736011754701)\n",
      "('f(1090.5077)', -1.1096838702190832)\n",
      "('f(1155.3527)', -1.1007409601285645)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_over, y_train_over, X_test_over, y_test_over, vars='freqs_reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.99\n",
      "  std dev: 0.02\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       168\n",
      "           1       1.00      0.99      0.99       173\n",
      "\n",
      "    accuracy                           0.99       341\n",
      "   macro avg       0.99      0.99      0.99       341\n",
      "weighted avg       0.99      0.99      0.99       341\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        30\n",
      "           1       1.00      0.97      0.98        31\n",
      "\n",
      "    accuracy                           0.98        61\n",
      "   macro avg       0.98      0.98      0.98        61\n",
      "weighted avg       0.98      0.98      0.98        61\n",
      "\n",
      "Coefficients:\n",
      "('TympType', 9.635430218956389)\n",
      "('OAE2', -0.44663605231535775)\n",
      "('OAE1.4', -0.369355808465783)\n",
      "('AgeY', 0.34800387696357304)\n",
      "('OAE4', -0.32919128417846055)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_over, y_train_over, X_test_over, y_test_over, vars='conts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 1.0\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4254\n",
      "           1       1.00      1.00      1.00      4246\n",
      "\n",
      "    accuracy                           1.00      8500\n",
      "   macro avg       1.00      1.00      1.00      8500\n",
      "weighted avg       1.00      1.00      1.00      8500\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       748\n",
      "           1       1.00      0.99      1.00       752\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_smote, y_train_smote, X_test_smote, y_test_smote, vars='reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.89\n",
      "  std dev: 0.01\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89      4497\n",
      "           1       0.86      0.91      0.89      4003\n",
      "\n",
      "    accuracy                           0.89      8500\n",
      "   macro avg       0.89      0.89      0.89      8500\n",
      "weighted avg       0.89      0.89      0.89      8500\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88       809\n",
      "           1       0.83      0.90      0.87       691\n",
      "\n",
      "    accuracy                           0.87      1500\n",
      "   macro avg       0.87      0.87      0.87      1500\n",
      "weighted avg       0.87      0.87      0.87      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_smote, y_train_smote, X_test_smote, y_test_smote, vars='freqs_reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 1.0\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4257\n",
      "           1       1.00      1.00      1.00      4243\n",
      "\n",
      "    accuracy                           1.00      8500\n",
      "   macro avg       1.00      1.00      1.00      8500\n",
      "weighted avg       1.00      1.00      1.00      8500\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       751\n",
      "           1       1.00      1.00      1.00       749\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "Coefficients:\n",
      "('TympType', 13.930901195413139)\n",
      "('SC', -1.1853309361542106)\n",
      "('ECV', -0.6685476761320475)\n",
      "('Ear coded', 0.6277536069583277)\n",
      "('OAE1.4', -0.5475101666330268)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_smote, y_train_smote, X_test_smote, y_test_smote, vars='conts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 1.0\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4254\n",
      "           1       1.00      1.00      1.00      4248\n",
      "\n",
      "    accuracy                           1.00      8502\n",
      "   macro avg       1.00      1.00      1.00      8502\n",
      "weighted avg       1.00      1.00      1.00      8502\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       745\n",
      "           1       1.00      0.99      1.00       756\n",
      "\n",
      "    accuracy                           1.00      1501\n",
      "   macro avg       1.00      1.00      1.00      1501\n",
      "weighted avg       1.00      1.00      1.00      1501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_adasyn, y_train_adasyn, X_test_adasyn, y_test_adasyn, vars='reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.97\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      4183\n",
      "           1       0.98      0.96      0.97      4319\n",
      "\n",
      "    accuracy                           0.97      8502\n",
      "   macro avg       0.97      0.97      0.97      8502\n",
      "weighted avg       0.97      0.97      0.97      8502\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       722\n",
      "           1       0.98      0.94      0.96       779\n",
      "\n",
      "    accuracy                           0.96      1501\n",
      "   macro avg       0.96      0.96      0.96      1501\n",
      "weighted avg       0.96      0.96      0.96      1501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_adasyn, y_train_adasyn, X_test_adasyn, y_test_adasyn, vars='freqs_reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 1.0\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4256\n",
      "           1       1.00      1.00      1.00      4246\n",
      "\n",
      "    accuracy                           1.00      8502\n",
      "   macro avg       1.00      1.00      1.00      8502\n",
      "weighted avg       1.00      1.00      1.00      8502\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       752\n",
      "           1       1.00      1.00      1.00       749\n",
      "\n",
      "    accuracy                           1.00      1501\n",
      "   macro avg       1.00      1.00      1.00      1501\n",
      "weighted avg       1.00      1.00      1.00      1501\n",
      "\n",
      "Coefficients:\n",
      "('TympType', 18.380907440895577)\n",
      "('ECV', -7.474618353318853)\n",
      "('OAE2', -0.8858288256618637)\n",
      "('Ear coded', -0.6759661386356035)\n",
      "('OAE1', -0.40201226376577437)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_adasyn, y_train_adasyn, X_test_adasyn, y_test_adasyn, vars='conts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC(C=10, gamma=0.001, random_state=42)\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.97\n",
      "  std dev: 0.03\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       160\n",
      "           1       1.00      0.97      0.98        31\n",
      "\n",
      "    accuracy                           0.99       191\n",
      "   macro avg       1.00      0.98      0.99       191\n",
      "weighted avg       0.99      0.99      0.99       191\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        42\n",
      "           1       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.96        48\n",
      "   macro avg       0.88      0.98      0.92        48\n",
      "weighted avg       0.97      0.96      0.96        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine(X_train_norm, y_train_norm, X_test_norm, y_test_norm, vars='reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC(C=0.1, gamma=0.1, kernel='poly', random_state=42)\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.94\n",
      "  std dev: 0.04\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       165\n",
      "           1       0.73      0.85      0.79        26\n",
      "\n",
      "    accuracy                           0.94       191\n",
      "   macro avg       0.85      0.90      0.87       191\n",
      "weighted avg       0.94      0.94      0.94       191\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        42\n",
      "           1       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.96        48\n",
      "   macro avg       0.88      0.98      0.92        48\n",
      "weighted avg       0.97      0.96      0.96        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine(X_train_norm, y_train_norm, X_test_norm, y_test_norm, vars='freqs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC(C=1, kernel='linear', random_state=42)\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.93\n",
      "  std dev: 0.04\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       167\n",
      "           1       0.67      0.83      0.74        24\n",
      "\n",
      "    accuracy                           0.93       191\n",
      "   macro avg       0.82      0.89      0.85       191\n",
      "weighted avg       0.94      0.93      0.93       191\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        42\n",
      "           1       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.96        48\n",
      "   macro avg       0.88      0.98      0.92        48\n",
      "weighted avg       0.97      0.96      0.96        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine(X_train_norm, y_train_norm, X_test_norm, y_test_norm, vars='freqs_reduced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC(C=10, kernel='linear', random_state=42)\n",
      "5-fold cross validation:\n",
      "  accuracy: 1.0\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4250\n",
      "           1       1.00      1.00      1.00      4250\n",
      "\n",
      "    accuracy                           1.00      8500\n",
      "   macro avg       1.00      1.00      1.00      8500\n",
      "weighted avg       1.00      1.00      1.00      8500\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       750\n",
      "           1       1.00      1.00      1.00       750\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine(X_train_over, y_train_over, X_test_over, y_test_over, vars='reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC(C=0.1, gamma=1, kernel='poly', random_state=42)\n",
      "5-fold cross validation:\n",
      "  accuracy: 1.0\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4250\n",
      "           1       1.00      1.00      1.00      4250\n",
      "\n",
      "    accuracy                           1.00      8500\n",
      "   macro avg       1.00      1.00      1.00      8500\n",
      "weighted avg       1.00      1.00      1.00      8500\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       750\n",
      "           1       1.00      1.00      1.00       750\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine(X_train_over, y_train_over, X_test_over, y_test_over, vars='freqs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC(C=0.1, gamma=0.1, kernel='poly', random_state=42)\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.94\n",
      "  std dev: 0.04\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       165\n",
      "           1       0.73      0.85      0.79        26\n",
      "\n",
      "    accuracy                           0.94       191\n",
      "   macro avg       0.85      0.90      0.87       191\n",
      "weighted avg       0.94      0.94      0.94       191\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        42\n",
      "           1       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.96        48\n",
      "   macro avg       0.88      0.98      0.92        48\n",
      "weighted avg       0.97      0.96      0.96        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine(X_train_norm, y_train_norm, X_test_norm, y_test_norm, vars='freqs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC(C=1000, kernel='linear', random_state=42)\n",
      "5-fold cross validation:\n",
      "  accuracy: 1.0\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4250\n",
      "           1       1.00      1.00      1.00      4250\n",
      "\n",
      "    accuracy                           1.00      8500\n",
      "   macro avg       1.00      1.00      1.00      8500\n",
      "weighted avg       1.00      1.00      1.00      8500\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       750\n",
      "           1       1.00      1.00      1.00       750\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine(X_train_smote, y_train_smote, X_test_smote, y_test_smote, vars='reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC(C=1, gamma=1, kernel='poly', random_state=42)\n",
      "5-fold cross validation:\n",
      "  accuracy: 1.0\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4250\n",
      "           1       1.00      1.00      1.00      4250\n",
      "\n",
      "    accuracy                           1.00      8500\n",
      "   macro avg       1.00      1.00      1.00      8500\n",
      "weighted avg       1.00      1.00      1.00      8500\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       750\n",
      "           1       1.00      1.00      1.00       750\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine(X_train_smote, y_train_smote, X_test_smote, y_test_smote, vars='freqs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC(C=1000, gamma=1, random_state=42)\n",
      "5-fold cross validation:\n",
      "  accuracy: 1.0\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4250\n",
      "           1       1.00      1.00      1.00      4250\n",
      "\n",
      "    accuracy                           1.00      8500\n",
      "   macro avg       1.00      1.00      1.00      8500\n",
      "weighted avg       1.00      1.00      1.00      8500\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       750\n",
      "           1       1.00      1.00      1.00       750\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine(X_train_smote, y_train_smote, X_test_smote, y_test_smote, vars='freqs_reduced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(X_train_adasyn, y_train_adasyn, X_test_adasyn, y_test_adasyn, vars='reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(X_train_adasyn, y_train_adasyn, X_test_adasyn, y_test_adasyn, vars='freqs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(X_train_adasyn, y_train_adasyn, X_test_adasyn, y_test_adasyn, vars='freqs_reduced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Generative Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(l1_ratio=0.0, penalty='none', random_state=42, solver='saga')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.97\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.97      9724\n",
      "         1.0       0.98      0.97      0.97     10076\n",
      "\n",
      "    accuracy                           0.97     19800\n",
      "   macro avg       0.97      0.97      0.97     19800\n",
      "weighted avg       0.97      0.97      0.97     19800\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.91        41\n",
      "         1.0       0.50      0.57      0.53         7\n",
      "\n",
      "    accuracy                           0.85        48\n",
      "   macro avg       0.71      0.74      0.72        48\n",
      "weighted avg       0.86      0.85      0.86        48\n",
      "\n",
      "Coefficients:\n",
      "('f(7127.1897)', 45.53271161255919)\n",
      "('f(458.5020)', -42.016059123072175)\n",
      "('f(1090.5077)', -28.263832468068955)\n",
      "('f(1296.8396)', 27.92044175988089)\n",
      "('f(577.6763)', -26.88719197356329)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_gen, y_train_gen, X_test_norm, y_test_norm, vars='freqs_reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.98\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      9687\n",
      "         1.0       0.99      0.97      0.98     10113\n",
      "\n",
      "    accuracy                           0.98     19800\n",
      "   macro avg       0.98      0.98      0.98     19800\n",
      "weighted avg       0.98      0.98      0.98     19800\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90        40\n",
      "         1.0       0.50      0.50      0.50         8\n",
      "\n",
      "    accuracy                           0.83        48\n",
      "   macro avg       0.70      0.70      0.70        48\n",
      "weighted avg       0.83      0.83      0.83        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_gen, y_train_gen, X_test_norm, y_test_norm, vars='reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(l1_ratio=0.0, penalty='none', random_state=42, solver='saga')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.97\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.97      9724\n",
      "         1.0       0.98      0.97      0.97     10076\n",
      "\n",
      "    accuracy                           0.97     19800\n",
      "   macro avg       0.97      0.97      0.97     19800\n",
      "weighted avg       0.97      0.97      0.97     19800\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.68      0.78        41\n",
      "         1.0       0.57      0.85      0.68        20\n",
      "\n",
      "    accuracy                           0.74        61\n",
      "   macro avg       0.73      0.77      0.73        61\n",
      "weighted avg       0.79      0.74      0.75        61\n",
      "\n",
      "Coefficients:\n",
      "('f(7127.1897)', 45.53271161255919)\n",
      "('f(458.5020)', -42.016059123072175)\n",
      "('f(1090.5077)', -28.263832468068955)\n",
      "('f(1296.8396)', 27.92044175988089)\n",
      "('f(577.6763)', -26.88719197356329)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_gen, y_train_gen, X_test_over, y_test_over, vars='freqs_reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.98\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      9687\n",
      "         1.0       0.99      0.97      0.98     10113\n",
      "\n",
      "    accuracy                           0.98     19800\n",
      "   macro avg       0.98      0.98      0.98     19800\n",
      "weighted avg       0.98      0.98      0.98     19800\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.74      0.81        38\n",
      "         1.0       0.67      0.87      0.75        23\n",
      "\n",
      "    accuracy                           0.79        61\n",
      "   macro avg       0.78      0.80      0.78        61\n",
      "weighted avg       0.81      0.79      0.79        61\n",
      "\n",
      "Coefficients:\n",
      "('f(458.5020)', -42.13786812963798)\n",
      "('f(7127.1897)', 38.81504487542164)\n",
      "('f(1296.8396)', 26.638339358573948)\n",
      "('f(1090.5077)', -24.570656736008107)\n",
      "('f(408.4789)', -22.82600463574783)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_gen, y_train_gen, X_test_over, y_test_over, vars='reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.98\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      9687\n",
      "         1.0       0.99      0.97      0.98     10113\n",
      "\n",
      "    accuracy                           0.98     19800\n",
      "   macro avg       0.98      0.98      0.98     19800\n",
      "weighted avg       0.98      0.98      0.98     19800\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.70      0.79       985\n",
      "         1.0       0.61      0.88      0.72       515\n",
      "\n",
      "    accuracy                           0.76      1500\n",
      "   macro avg       0.76      0.79      0.76      1500\n",
      "weighted avg       0.81      0.76      0.77      1500\n",
      "\n",
      "Coefficients:\n",
      "('f(458.5020)', -42.13786812963798)\n",
      "('f(7127.1897)', 38.81504487542164)\n",
      "('f(1296.8396)', 26.638339358573948)\n",
      "('f(1090.5077)', -24.570656736008107)\n",
      "('f(408.4789)', -22.82600463574783)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_gen, y_train_gen, X_test_smote, y_test_smote, vars='reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(l1_ratio=0.0, penalty='none', random_state=42, solver='saga')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.97\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.97      9724\n",
      "         1.0       0.98      0.97      0.97     10076\n",
      "\n",
      "    accuracy                           0.97     19800\n",
      "   macro avg       0.97      0.97      0.97     19800\n",
      "weighted avg       0.97      0.97      0.97     19800\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.68      0.78      1003\n",
      "         1.0       0.58      0.87      0.70       497\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.75      0.78      0.74      1500\n",
      "weighted avg       0.80      0.75      0.75      1500\n",
      "\n",
      "Coefficients:\n",
      "('f(7127.1897)', 45.53271161255919)\n",
      "('f(458.5020)', -42.016059123072175)\n",
      "('f(1090.5077)', -28.263832468068955)\n",
      "('f(1296.8396)', 27.92044175988089)\n",
      "('f(577.6763)', -26.88719197356329)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_gen, y_train_gen, X_test_smote, y_test_smote, vars='freqs_reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.98\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      9687\n",
      "         1.0       0.99      0.97      0.98     10113\n",
      "\n",
      "    accuracy                           0.98     19800\n",
      "   macro avg       0.98      0.98      0.98     19800\n",
      "weighted avg       0.98      0.98      0.98     19800\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.65      0.77      1079\n",
      "         1.0       0.50      0.89      0.64       422\n",
      "\n",
      "    accuracy                           0.72      1501\n",
      "   macro avg       0.72      0.77      0.71      1501\n",
      "weighted avg       0.82      0.72      0.73      1501\n",
      "\n",
      "Coefficients:\n",
      "('f(458.5020)', -42.13786812963798)\n",
      "('f(7127.1897)', 38.81504487542164)\n",
      "('f(1296.8396)', 26.638339358573948)\n",
      "('f(1090.5077)', -24.570656736008107)\n",
      "('f(408.4789)', -22.82600463574783)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_gen, y_train_gen, X_test_adasyn, y_test_adasyn, vars='reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegression(l1_ratio=0.0, penalty='none', random_state=42, solver='saga')\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.97\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.97      9724\n",
      "         1.0       0.98      0.97      0.97     10076\n",
      "\n",
      "    accuracy                           0.97     19800\n",
      "   macro avg       0.97      0.97      0.97     19800\n",
      "weighted avg       0.97      0.97      0.97     19800\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.64      0.76      1089\n",
      "         1.0       0.48      0.87      0.62       412\n",
      "\n",
      "    accuracy                           0.70      1501\n",
      "   macro avg       0.70      0.76      0.69      1501\n",
      "weighted avg       0.81      0.70      0.72      1501\n",
      "\n",
      "Coefficients:\n",
      "('f(7127.1897)', 45.53271161255919)\n",
      "('f(458.5020)', -42.016059123072175)\n",
      "('f(1090.5077)', -28.263832468068955)\n",
      "('f(1296.8396)', 27.92044175988089)\n",
      "('f(577.6763)', -26.88719197356329)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train_gen, y_train_gen, X_test_adasyn, y_test_adasyn, vars='freqs_reduced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC(C=100, gamma=1, kernel='poly', random_state=42)\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.98\n",
      "  std dev: 0.0\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      9698\n",
      "         1.0       0.99      0.97      0.98     10102\n",
      "\n",
      "    accuracy                           0.98     19800\n",
      "   macro avg       0.98      0.98      0.98     19800\n",
      "weighted avg       0.98      0.98      0.98     19800\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.90      0.89        39\n",
      "         1.0       0.50      0.44      0.47         9\n",
      "\n",
      "    accuracy                           0.81        48\n",
      "   macro avg       0.69      0.67      0.68        48\n",
      "weighted avg       0.80      0.81      0.81        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine(X_train_gen, y_train_gen, X_test_norm, y_test_norm, vars='freqs_reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC(C=100, kernel='linear', random_state=42)\n",
      "5-fold cross validation:\n",
      "  accuracy: 0.97\n",
      "  std dev: 0.01\n",
      "Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98       510\n",
      "         1.0       0.99      0.97      0.98       490\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.98      0.98      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.92      0.87        36\n",
      "         1.0       0.62      0.42      0.50        12\n",
      "\n",
      "    accuracy                           0.79        48\n",
      "   macro avg       0.72      0.67      0.68        48\n",
      "weighted avg       0.78      0.79      0.78        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine(X_train_gen[:1000], y_train_gen[:1000], X_test_norm, y_test_norm, vars='reduced')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
